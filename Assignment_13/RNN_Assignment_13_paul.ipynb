{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "75VOiRumbtCW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Text Generation with RNNs\n",
    "https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
    "\n",
    "https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/\n",
    "\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q-eZcyy_btCX",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kwc0o4bGbtCa"
   },
   "source": [
    "### 1 Dataset\n",
    "Define the path of the file, you want to read and train the model on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_-pWsSdWbtCb",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''TODO: set the path of the file'''\n",
    "path_to_file = 'Shakespeare_karpathy.txt'\n",
    "text = open(path_to_file, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku1gyuOibtCd"
   },
   "source": [
    "\n",
    "#### Inspect the dataset\n",
    "Take a look at the first 250 characters in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOoE3ZLwbtCe",
    "outputId": "d30070f9-75aa-418e-eec7-1c88ef4c5a88",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That, poor contempt, or claim'd thou slept so faithful,\n",
      "I may contrive our father; and, in their defeated queen,\n",
      "Her flesh broke me and puttance of expedition house,\n",
      "And in that same that ever I lament this stomach,\n",
      "And he, nor Butly and my fury, kno\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixxZ4yBqbtCh",
    "outputId": "35130043-41cc-49f9-aceb-a82f07b9fdeb",
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luvcRu86btCj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2 Process the dataset for the learning task\n",
    "The task that we want our model to achieve is: given a character, or a sequence of characters, what is the most probable next character?\n",
    "\n",
    "To achieve this, we will input a sequence of characters to the model, and train the model to predict the output, that is, the following character at each time step. RNNs maintain an internal state that depends on previously seen elements, so information about all characters seen up until a given moment will be taken into account in generating the prediction.\n",
    "\n",
    "#### Vectorize the text\n",
    "Before we begin training our RNN model, we'll need to create a numerical representation of our text-based dataset. To do this, we'll generate two lookup tables: one that maps characters to numbers, and a second that maps numbers back to characters. Recall that we just identified the unique characters present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7koc3Q2dbtCk",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# Create a mapping from indices to characters\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s04cWuBCbtCm"
   },
   "source": [
    "\n",
    "This gives us an integer representation for each character. Observe that the unique characters (i.e., our vocabulary) in the text are mapped as indices from 0 to len(unique). Let's take a peek at this numerical representation of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Rbt2hfpbtCn",
    "outputId": "2b2898f6-0e0f-47c9-f9a5-a7c89a09376e",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  \"'\" :   3,\n",
      "  ',' :   4,\n",
      "  '-' :   5,\n",
      "  '.' :   6,\n",
      "  ':' :   7,\n",
      "  ';' :   8,\n",
      "  '?' :   9,\n",
      "  'A' :  10,\n",
      "  'B' :  11,\n",
      "  'C' :  12,\n",
      "  'D' :  13,\n",
      "  'E' :  14,\n",
      "  'F' :  15,\n",
      "  'G' :  16,\n",
      "  'H' :  17,\n",
      "  'I' :  18,\n",
      "  'J' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dsh270g9btCp"
   },
   "source": [
    "\n",
    "\n",
    "We can also look at how the first part of the text is mapped to an integer representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egRTUKhlbtCq",
    "outputId": "1207e303-3557-4408-815e-ee26fdcbc04f",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'That, poor co' ---- characters mapped to int ---- > [29 43 36 55  4  1 51 50 50 53  1 38 50]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fti3o5GHbtCs"
   },
   "source": [
    "#### Defining a method to encode one hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oef5BSBpbtCt",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "\n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxoJlIhmbtCw"
   },
   "source": [
    "\n",
    "#### Defining a method to make mini-batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1JNdq5YgbtCw",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "\n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    # total number of batches we can make\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    # iterate through the array, one sequence at a time\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        # The features\n",
    "        x = arr[:, n:n + seq_length]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n + seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHoy0u0abtCz"
   },
   "source": [
    "\n",
    "## 3 The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tkdc8Z6VbtC0"
   },
   "source": [
    "\n",
    "###### Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wRmMM9kbtC0",
    "outputId": "a6a7802d-ab6f-47b8-c1d3-0ebaa6d2f3a2",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "print ('Training on GPU' if train_on_gpu else 'Training on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4b7JO6FbtC3"
   },
   "source": [
    "\n",
    "### Declaring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k72_pm6obtC3",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VanillaCharRNN(nn.Module):\n",
    "    def __init__(self, vocab, n_hidden=256, n_layers=2,\n",
    "                 drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.rnn = nn.RNN(len(self.vocab), self.n_hidden, self.n_layers, batch_first=True, dropout=self.drop_prob)   #batch_first=True -> input and output tensors are provided as (batch, seq, feature)\n",
    "        self.fc = nn.Linear(self.n_hidden, len(self.vocab))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        # x of shape (seq_len, batch, input_size)\n",
    "        # hidden of shape (num_layers * num_directions, batch, hidden_size)\n",
    "        out, hidden_t = self.rnn(x, hidden)\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden_t\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.n_hidden)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eKFZqqjw013I"
   },
   "outputs": [],
   "source": [
    "class LSTMCharRNN(nn.Module):\n",
    "    def __init__(self, vocab, n_hidden=256, n_layers=2,\n",
    "                 drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.vocab), self.n_hidden, self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
    "        self.fc = nn.Linear(self.n_hidden, len(self.vocab))\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        hidden_state = torch.zeros(self.n_layers, batch_size, self.n_hidden).cuda()\n",
    "        cell_state = torch.zeros(self.n_layers, batch_size, self.n_hidden).cuda()\n",
    "        # cell state should be included as for now the model only backpropagates the loss over the hidden states and not the cell states\n",
    "        return (hidden_state, cell_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD6AFo9zbtC8"
   },
   "source": [
    "\n",
    "#### Declaring the train method\n",
    "\n",
    "\n",
    "train(vanilla_model, text_as_int, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "S2HKSmmAbtC9",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "\n",
    "        model: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "\n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data) * (1 - val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "\n",
    "    if (train_on_gpu):\n",
    "        model.cuda()\n",
    "\n",
    "    counter = 0\n",
    "    n_vocab = len(model.vocab)\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "        \n",
    "        '''TODO: use the get_batches function to generate sequences of the desired size'''\n",
    "        dataset = get_batches(data, batch_size, seq_length)\n",
    "\n",
    "        for x, y in dataset:\n",
    "            counter += 1\n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_vocab)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "            if (train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            if type(h) is tuple:\n",
    "                if train_on_gpu:\n",
    "                    h = tuple([each.data.cuda() for each in h])\n",
    "                else:\n",
    "                    h = tuple([each.data for each in h])\n",
    "            else:\n",
    "                if train_on_gpu:\n",
    "                    h = h.data.cuda()\n",
    "                else:\n",
    "                    h = h.data\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            output, h = model(inputs, h) \n",
    "            loss = criterion(output, targets.view(-1).long())\n",
    "            \n",
    "            # perform backprop\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = model.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_vocab)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    if type(val_h) is tuple:\n",
    "                        if train_on_gpu:\n",
    "                            val_h = tuple([each.data.cuda() for each in val_h])\n",
    "                        else:\n",
    "                            val_h = tuple([each.data for each in val_h])\n",
    "                    else:\n",
    "                        if train_on_gpu:\n",
    "                            val_h = val_h.data.cuda()\n",
    "                        else:\n",
    "                            val_h = val_h.data\n",
    "\n",
    "                    inputs, targets = x, y\n",
    "                    if (train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    output, val_h = model(inputs, val_h)\n",
    "\n",
    "                    val_loss = criterion(output, targets.view(-1).long())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "                \n",
    "                input_eval = 'Dear'\n",
    "                print(sample(model, 1000, prime=input_eval, top_k=10))\n",
    "                \n",
    "                model.train()  # reset to train mode after iterationg through validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtlmj6sAbtC_"
   },
   "source": [
    "\n",
    "##### Defining a method to generate the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eTDAUosNbtC_",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, char, h=None, top_k=None):\n",
    "    ''' \n",
    "    Given a character, predict the next character.\n",
    "    Returns the predicted character and the hidden state.\n",
    "    '''\n",
    "\n",
    "    # tensor inputs\n",
    "    x = np.array([[char2idx[char]]])\n",
    "    x = one_hot_encode(x, len(model.vocab))\n",
    "    inputs = torch.from_numpy(x)\n",
    "    \n",
    "    if (train_on_gpu):\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    # detach hidden state from history\n",
    "    if type(h) is tuple:\n",
    "        if train_on_gpu:\n",
    "            h = tuple([each.data.cuda() for each in h])\n",
    "        else:\n",
    "            h = tuple([each.data for each in h])\n",
    "    else:\n",
    "        if train_on_gpu:\n",
    "            h = h.data.cuda()\n",
    "        else:\n",
    "            h = h.data\n",
    "    output, h = model(inputs, h)\n",
    "\n",
    "    # get the character probabilities\n",
    "    p = F.softmax(output, dim=1).data\n",
    "    if (train_on_gpu):\n",
    "        p = p.cpu()  # move to cpu\n",
    "\n",
    "    # get top characters\n",
    "    if top_k is None:\n",
    "        top_ch = np.arange(len(model.vocab))\n",
    "    else:\n",
    "        p, top_ch = p.topk(top_k)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "\n",
    "    # select the likely next character with some element of randomness\n",
    "    p = p.numpy().squeeze()\n",
    "    char = np.random.choice(top_ch, p=p / p.sum())\n",
    "\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return idx2char[char], h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a_I3GHqbtDB"
   },
   "source": [
    "\n",
    "#### Declaring a method to generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mS9UcwBXbtDC",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample(model, size, prime='The', top_k=None):\n",
    "    if (train_on_gpu):\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "\n",
    "    model.eval()  # eval mode\n",
    "\n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = model.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(model, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, char, h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    model.train()\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viwhJM9RbtDE"
   },
   "source": [
    "\n",
    "#### Generate new Text using the RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7bc2y3DbtDE"
   },
   "source": [
    "###### Define and print the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHbAsHB2btDF",
    "outputId": "5800faa9-65d4-4ae0-999b-deeada7e7d4b",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaCharRNN(\n",
      "  (rnn): RNN(62, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=256, out_features=62, bias=True)\n",
      ")\n",
      "LSTMCharRNN(\n",
      "  (lstm): LSTM(62, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (fc): Linear(in_features=256, out_features=62, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''''TODO: Try changing the number of units in the network to see how it affects performance'''\n",
    "n_hidden = 256\n",
    "n_layers = 2\n",
    "\n",
    "vanilla_model = VanillaCharRNN(vocab, n_hidden, n_layers)\n",
    "print(vanilla_model)\n",
    "lstm_model = LSTMCharRNN(vocab, n_hidden, n_layers)\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-sU3cQIbtDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "###### Declaring the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ZJnyYkQlbtDJ",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''''TODO: Try changing the hyperparameters in the network to see how it affects performance'''\n",
    "batch_size = 50\n",
    "seq_length = 50\n",
    "n_epochs = 20  # start smaller if you are just testing initial behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46LJ32XHbtDM"
   },
   "source": [
    "\n",
    "##### Train the model and have fun with the generated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Bzc7Dz65FOPs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Step: 50... Loss: 1.4080... Val Loss: 1.7587\n",
      "Dear spaence thingion.\n",
      "\n",
      "MARK ANTONY:\n",
      "O had it, and there is betument of thy mather of suffench another\n",
      "Head my ground and belick'd:\n",
      "But well in a ganmon so be oartes.\n",
      "\n",
      "HELENA:\n",
      "Alas, so stor blind the way blunt and heart,\n",
      "And that talks, as honour would,\n",
      "See so brother's a frown-by your guilous whife will put you know when the dutch your crafain\n",
      "A hands are passage, his amoul from our mander's tought me.\n",
      "\n",
      "DUKE OF DOUGLAS:\n",
      "That the way\n",
      "Shall now all thee atter the part; but you we have sin and thee take with a speekings\n",
      "When I may ame.\n",
      "\n",
      "Second Lord:\n",
      "\n",
      "MALVOLIO:\n",
      "A part,\n",
      "Then would not give another te's full,\n",
      "But your cried,\n",
      "And blother:\n",
      "Let I have thy say, and first which his baur you a speak my braves arm the gud my be sure;\n",
      "And to hast have that that thy very mysee so,\n",
      "For them; and there's good storn and since\n",
      "To day,\n",
      "Good dead\n",
      "To make your come the hands. Let thee to die fire offent shall do buces and alsow all theat his stain to the fallaan\n",
      "By the streemn that say your seaser's reasment,\n",
      "W\n",
      "Epoch: 3/20... Step: 100... Loss: 1.3541... Val Loss: 1.7537\n",
      "Dear hunds, his reserding wirmant their rast, like eye in their post sweet like a flued sir Julius and was\n",
      "I think'st, and my death in this son, I would not him, a sament with her, what sweet of the field,\n",
      "They you would.\n",
      "\n",
      "PATT FARD:\n",
      "I was take your sans this well, so fantle, tell wence my to brancentable, we, or he part,\n",
      "Him to they sit of the world\n",
      "They he were clames, and from Rome thr salien lufe,\n",
      "Havion in a geeper till.\n",
      "\n",
      "PISTOL:\n",
      "Sir; I knoth a longuse me these falcars,\n",
      "Which of luciant\n",
      "But, afal staint:\n",
      "Not my liges: I am as great me to the present, thot I should,\n",
      "We may dont by his ears and led me in a spake\n",
      "An I should I must have hink the wisd; and wasce your hands of a more may as this phese:\n",
      "We have that was for my feard she's brother, it on ducius my penarem, and them fear'st saver thrower with a trained, made alamish again. Shall be as you letter morrows and deliver thee, will not my say! yet in the stay;\n",
      "And wile we prove hand triting me to bear it saw it me;\n",
      "And my gates. Is'\n",
      "Epoch: 5/20... Step: 150... Loss: 1.4283... Val Loss: 1.7547\n",
      "Dear again, and thus fall me well, my heart: and, I am a perfeen he swear could, let us we prince:\n",
      "If I must not which you have dreth baise: I am as I be so my sister batwering his poirs in my tould now him glaunstain, that well you may like:\n",
      "And thou not them in daughter:\n",
      "There it makent matherer him:\n",
      "A prays of these fants to give an another days.\n",
      "\n",
      "KING CLAUDIUS:\n",
      "\n",
      "CASSIAN:\n",
      "I'll some disjections, my lord. I know not, but there elongs and shall be bange\n",
      "Snow as I am not the duke besoland; tier to again to the simply.\n",
      "\n",
      "AUFELINE:\n",
      "But they such of this; yiu hather good as he has not he'g his roish\n",
      "Thou art and fants, the pariess, and ingen of me, my lord, I will hearted batding for thee in my sakes and a gonly.\n",
      "\n",
      "PANDAR DOUGHALO:\n",
      "Ay, swell thee, and a bear, to heart a words of a wombor before with to heavens and gold, and sugure-bear him gently well,\n",
      "When your glove,\n",
      "They sent the world, from my stepore.\n",
      "\n",
      "CLEOPATRA:\n",
      "What is had blush will see then think no cracking, a fallow. Remand, whose woul\n",
      "Epoch: 6/20... Step: 200... Loss: 1.3663... Val Loss: 1.7537\n",
      "Dear, I am confiring break our perpiciss:\n",
      "Your broad\n",
      "Hath doth kind stand.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "My, I have stope; puratns,\n",
      "Nems from my lew it one:\n",
      "O villain. To bristers.\n",
      "Bull state of thy besaing and chargy of the command wither on my penituer and her good perdar Sut your way, with her stroked?\n",
      "\n",
      "AJAX:\n",
      "Fair togethre forbour to dise, that him, my lord; your better have deliver of the curriaus before was too myself have book, they\n",
      "shourd in\n",
      "Shill hold, when shall not glade and see: I'll seat\n",
      "Much banistires.\n",
      "\n",
      "ANGELO:\n",
      "Wearous one of hers: myson and thus seeming well; look whill or the case\n",
      "In her beseeco was of a good caid then,\n",
      "Frind thee grevens too follow. He she we arms.\n",
      "\n",
      "LEONATO:\n",
      "Alas you will be bring messe ther.\n",
      "\n",
      "BRUTUS:\n",
      "Well,\n",
      "Be my stake thou a prese as we\n",
      "To her late again.\n",
      "\n",
      "CORIOLANUS:\n",
      "I know trouls in their plince an thy perrow? her heaven toldy use you do would,\n",
      "And pather well.\n",
      "\n",
      "CRESSIDA:\n",
      "There at she will prove thou lost bodld hath hoped tash'd will he stop his seat\n",
      "But I weilfotl s\n",
      "Epoch: 8/20... Step: 250... Loss: 1.3881... Val Loss: 1.7532\n",
      "Dearsher, I maint in this rage.\n",
      "\n",
      "MARK ANTONY:\n",
      "Ooch my seeming man as thinken and begg'd, she wouldst\n",
      "Their father's feer, I have man, and star of thus bland, and hear it.\n",
      "\n",
      "SPEED:\n",
      "Thou his giolly to be hous? seme thind o'er\n",
      "And heads of my dearer and his broods not field\n",
      "That is mich an is,\n",
      "In here a triend as I am said as might come to atchief I must not deliver\n",
      "But should did bloody hence army all to you. But thou lady so.\n",
      "\n",
      "ALARLINU:\n",
      "I'll speak truly.\n",
      "\n",
      "CLEOPATRA:\n",
      "\n",
      "MARIACS:\n",
      "What I shrong at thou did but you, if the hence, his and\n",
      "Bresience blother, fars are, for when I would neart a perition of this speak to the glay her to see thou best honours, that she's not with let like and motion of truerd.\n",
      "\n",
      "PORIOLA:\n",
      "The world, by the dime: you heart, his brought me and a beliepe;\n",
      "A scancelongs friendy to came, and the soncle the fellow, and then he loves and guilts, and sich but well, who dost friendshiptect my foederal dost for offer me; and made, I hows the which are dost a friaterable.\n",
      "\n",
      "ALBANY:\n",
      "Fo\n",
      "Epoch: 9/20... Step: 300... Loss: 1.4287... Val Loss: 1.7576\n",
      "Dear Sight\n",
      "That should not\n",
      "geet sir,\n",
      "That tent, his guiliot,\n",
      "But here thou, the shell;\n",
      "We have-hen oak agailed doubted, that would before your stire of an him.\n",
      "\n",
      "COUNTESS:\n",
      "So's them holes, and brother on mige:'s accusand,\n",
      "That thind the heavens of death humber single see it not take he that speak,\n",
      "As he most no more'ck and thee thee, been him see me\n",
      "And some look not he shall\n",
      "I have an ourselved had boss\n",
      "Paised hitherdy come to the bose to the fice,\n",
      "And heaven af this fuor the sunt the sunger.\n",
      "\n",
      "KING HENRY V:\n",
      "I stay'd\n",
      "England again, you, he knith, the paesiage streets\n",
      "Book bat 's place, they are to this:\n",
      "To the horse, and thing\n",
      "As I way in thy crief?\n",
      "\n",
      "AURE PINIA:\n",
      "He till my death.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Thy hest such me, the swe shame:\n",
      "But, sir, I should been humself so furs,\n",
      "Must good\n",
      "England\n",
      "The have\n",
      "Twrous'd and prove some-fortuse she hastrs, that's you with thy boy,--O mold desire to my llave\n",
      "To make them actide swear to sleath, though it.\n",
      "\n",
      "Clown:\n",
      "To so betser bear.\n",
      "\n",
      "CRINCE:\n",
      "She was a man's pro\n",
      "Epoch: 10/20... Step: 350... Loss: 1.4876... Val Loss: 1.7599\n",
      "Dear them crinct\n",
      "Marswhile more the song,\n",
      "Stay, and but youth without thy chamber\n",
      "That the dearer about a spurt is the dut would sat thee; as I hear mest fousiness,\n",
      "That he be them and army before the dumpst her first to be your god. Lood lord,\n",
      "Then to do ene those tame\n",
      "In more that these foltculor's the heave and stree\n",
      "Ant title?\n",
      "\n",
      "LiEstnd\n",
      "By Rome and hear of my fortunes action, with him,\n",
      "And he whose prayer, as is no love, that how now, if the fullow'd me whose come, that he before to me servingment, and be to thee, my gentle but my pure of such again.\n",
      "\n",
      "First Lord:\n",
      "The world\n",
      "To make it nothing our horband mirrung fit to see your taught:\n",
      "Who all reseine to-never, liest of heavens a casked minester.\n",
      "\n",
      "DEONATO:\n",
      "What action;\n",
      "For't some show a huntred\n",
      "Of thy chnee;\n",
      "And mugion to misdrby with my majesty prince I am sure tell your hand that it soft, who's stars, thought her,\n",
      "Or we loves would\n",
      "I have many ast.\n",
      "\n",
      "BORHAND:\n",
      "No, some languint that I am dight\n",
      "That was to prince, if I tendent himself said\n",
      "Epoch: 12/20... Step: 400... Loss: 1.3349... Val Loss: 1.7551\n",
      "Dear of the fair.\n",
      "\n",
      "Surond:\n",
      "Yese legd, and to brainsefs of the show and seat of a may:\n",
      "That is not be more'n as gold as he was some but there should be your heart have again, and I may good himself here in see let me the headt bear and golding my friends, looks bloce you: but for knesband to case survings,\n",
      "If he day\n",
      "To thou no still prove the sleepry wife one and behinds, the fail and daeferainme, which now what's met his party, to thy siby most but you sea-dain\n",
      "Me winget thee, you will do couls, sir: he knows nave stody chambers.\n",
      "\n",
      "HENRY BOLING:\n",
      "He did well be swearnd in spease to-night, the bloody, but I can efelient speak it.\n",
      "\n",
      "CORIOLANUS:\n",
      "He knows.\n",
      "\n",
      "BRUTUS:\n",
      "O,\n",
      "I sware to muke\n",
      "That thy husbander.\n",
      "\n",
      "SPRONIO:\n",
      "But, for my father bretus my brother, a furshean more of the welleable sorrion of the fire, and he beard to myself to cours and all this mear that the gut my house thee the fauth of any worns face, and what have with the pleasure, thy bearded lord,\n",
      "Look her discont show now, call my secre\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Step: 450... Loss: 1.3008... Val Loss: 1.7561\n",
      "Dear them fon will fall my house; she do not should be prigion,\n",
      "And man were you words may be prick that is the world can change to be treature;\n",
      "Tirn the crom they arge\n",
      "For care trepering out,\n",
      "Murture's mecrion:\n",
      "Let us all this present face down that desmed, I have bloody of thee, I will not;\n",
      "First. Brutus that every to all the world un their pity, and I would never days: I thought, and throwers,\n",
      "Plecks; it, as men flint all.\n",
      "Himself it nature, when I have done had them to a spirit\n",
      "Wat would said\n",
      "I shall fellour flonces.\n",
      "\n",
      "DONTA:\n",
      "Ay, to life fors to stopperous some it was shake him, have stay'd are provise in tert us wit, my flad it satiog, whose take thee in the gadst\n",
      "As tongheling of the body and great should not gain dim as have I mept to day, I have a mone melanched to you may gages:\n",
      "Never feerly done thy heart,\n",
      "Wro sains's heaven for I'll send of men as thine and good people; my let to the cause out\n",
      "And speet with their peace.\n",
      "By your gracos with a love her draught me; prithee in thy fe\n",
      "Epoch: 15/20... Step: 500... Loss: 1.3865... Val Loss: 1.7554\n",
      "Dear Masterees, I have a foil of trushand to steps horriare, sir as great of locks.\n",
      "\n",
      "HELLOT:\n",
      "The deed of my boy.\n",
      "\n",
      "BRUTUS:\n",
      "O has to sister\n",
      "Lose as my siffolk brought with thee, patter than man wance on least thou see, thou art to the fill or them.\n",
      "\n",
      "KING LEAR:\n",
      "\n",
      "KING OF YORK:\n",
      "A very desarate;\n",
      "That do you shall not go seen\n",
      "Ed his bloody straight.\n",
      "\n",
      "Second Lord:\n",
      "Thy hand your come in the call me you to be bloody: I have with some lrother!\n",
      "\n",
      "OLCENIUS:\n",
      "O heart.\n",
      "\n",
      "RUNEINE:\n",
      "A were commif'er with her hepent, for made thee, I will hit is not, I will\n",
      "My lord; and no caulsting be so you: not have their heads, they will saw these stay I have by all them we wouldow it in the glor ore exame to be is not,\n",
      "And mad and majesty,\n",
      "Herself do be a look, then I do not through dost to did amper'n; I do you gone:\n",
      "If we lord,\n",
      "And like an seemer: and bring\n",
      "To loyguns,\n",
      "To han not fire of melitted fures thee; I will be some chore of your shame.\n",
      "\n",
      "MARK ANTRANIO:\n",
      "If her hapen not all thee\n",
      "Of my butied, I shall I'll findlats o\n",
      "Epoch: 16/20... Step: 550... Loss: 1.3379... Val Loss: 1.7612\n",
      "Dears:\n",
      "I his homseralds in she, I have what you will. I heard shall present over saens.\n",
      "\n",
      "BARDOLANUS:\n",
      "My vila my reasont\n",
      "Till montel that sent thee,\n",
      "That would be is were me with your fellow is we may which anle,\n",
      "He sha not becouls with way; must before you.\n",
      "\n",
      "PETELLE:\n",
      "Where's gloce's my face, if he had base arms.\n",
      "\n",
      "GLOUCESTER:\n",
      "But by the chaid their saids.\n",
      "\n",
      "First Gone: Perroage;\n",
      "Nor good world saw other through head this sweetly\n",
      "Was days,\n",
      "So you will die, which this poor offed so, welcome think, but I love, sweet his hape,\n",
      "So say I live silend tit of thee, it weep hold her day 'mone not to the boons, and I can, and two mile him blicker's mind had true that fair thee all?'\n",
      "\n",
      "LAPE:\n",
      "Sir, horonity's takes the lipertaral'd\n",
      "To come to the poor our men it my boys are for this?\n",
      "\n",
      "DUKE VIMLES:\n",
      "Thou hose any to me. Young presently.\n",
      "\n",
      "DOMELIA:\n",
      "We had not body my lord, she should state\n",
      "The ledy!\n",
      "\n",
      "Second Mimsons, thy hand will not so have a true that\n",
      "I would, you must stay thy brancted that for my scorn; tho\n",
      "Epoch: 18/20... Step: 600... Loss: 1.3611... Val Loss: 1.7659\n",
      "Dears it to beseecish well abmost, sir; I'll silied, but I was did the hoase.\n",
      "\n",
      "BASTIAN:\n",
      "Where wat\n",
      "I lope, man, hot met, I think thou art a master at the dears being of be still my lord; to my good chouched\n",
      "Look with true, though your beseed,\n",
      "But what is well; will silman.\n",
      "\n",
      "MENENIUS:\n",
      "Then now for with\n",
      "do cell thy fave need and therefore in the fixed? so go to you are\n",
      "The wipmon work and head to make the ways,\n",
      "Of thy beserfore field, I prother.\n",
      "\n",
      "CASSIUS:\n",
      "A mert\n",
      "As him with my tho performs'd that feet\n",
      "Thy pixchares the waserabunemoush, crom's his he dreaster, and that he's more, for I will hear.\n",
      "\n",
      "OuTOLINCE:\n",
      "Sir, I have my fear: have giees to good langused by his coxty of he pay to hit, my forewalk and the drougetance the weaved and through to do.\n",
      "\n",
      "PRITEUINENUS:\n",
      "And be mings,\n",
      "To my lord; I kneeld to tre desisent was fair, then to conventens and as great me,\n",
      "To hope thingh\n",
      "There's beseiple back to did and we'ls now cousin, be no house, the destrance,\n",
      "I am offerly as a part a woman.\n",
      "\n",
      "CRESSIDA:\n",
      "To\n",
      "Epoch: 19/20... Step: 650... Loss: 1.3967... Val Loss: 1.7622\n",
      "Dear your give his east the blame they causar, more a praised hy prepthough not my trink her break for which belain.\n",
      "\n",
      "CISS:\n",
      "Arun this house: why, trone, is too by rather be such me.\n",
      "You have also so she shall not speak from me your feit the forficed of thou ghink of these sovereit,\n",
      "In to load thou do with me, pairing\n",
      "From the field\n",
      "That you do\n",
      "Horicy all offence.'\n",
      "\n",
      "MISTELCSEY'US:\n",
      "But then your party on your lear of all this comp twe tappies, the which, my lord,\n",
      "So vouch had heaven my racreat a think this with a wound\n",
      "you so beast they have so to you, if a love that was dowercour we are, that thy falsely wish the fool content: who shreelf so stopm speak.\n",
      "\n",
      "Tilnt Gake his give thy death\n",
      "If we art the friend and make him by the first bear that full observalie,\n",
      "Why thoughts,\n",
      "Shal me now to have alow's love of them to can you would see him go.\n",
      "\n",
      "CARDINARIUS:\n",
      "Ay, sir, so so so fair the world, and show that his cours:\n",
      "Your chown, mardies, and I do break to compictiat at me,\n",
      "The parlonged\n",
      "Of thou hol\n",
      "Epoch: 20/20... Step: 700... Loss: 1.4542... Val Loss: 1.7632\n",
      "Dear, as there and\n",
      "The who foil of misius to the will you\n",
      "go his should at lust.\n",
      "Pray it to be in the loss; and I besee\n",
      "Of my feethy hath to be as hot my read tay\n",
      "That is this ways; and her dead, hopbealy\n",
      "Marry, I know the simple\n",
      "The palted, where's not\n",
      "Tay his boss in some thus is the husband.\n",
      "Weat has good to me, I, can again;\n",
      "Why blave of the heaven of thee.\n",
      "\n",
      "Second Gentleman:\n",
      "Ar whose tards of a city a seem;\n",
      "That thou hases soon. Telasure on love, since another fortund,\n",
      "The bady to speak to seld oullr of men in the hitchsence you thine own the song,\n",
      "As has to her live him, what oft to place.\n",
      "\n",
      "BESTRINCE:\n",
      "With our conviny,\n",
      "I ar, so foar sort and brush childrens that for to me,--\n",
      "\n",
      "KING HENRY V:\n",
      "In eldonar's heart,\n",
      "Same so he dince to the ciscussieve thee a propers, and thee\n",
      "Holert of must I mode their behind leghour might pitions me,\n",
      "I'll streatent of siren and them the charging may like takioff tide to speak would I am so villain, bitter a did but thee,\n",
      "Broud too beseets of his amtis stop\n"
     ]
    }
   ],
   "source": [
    "train(vanilla_model, text_as_int, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdBcUbv6FObG",
    "outputId": "954cf9d0-f536-45c5-ba90-b0e0a153d61e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Step: 50... Loss: 0.7554... Val Loss: 2.2096\n",
      "Dear:\n",
      "No, I opher; uncle my lord,\n",
      "And hang make yet face; and in the enemy,\n",
      "When he in a gooding some goodness I tole;\n",
      "Then thy I am breath.\n",
      "Though her dearly courtest towers, and single\n",
      "Wills dir to his oaths over desire,\n",
      "Who make never I scave a layful place.\n",
      "Here comes theme upon the world?\n",
      "\n",
      "DUKE OF YORK:\n",
      "More than are port in this tame.\n",
      "\n",
      "MOLOF:\n",
      "And that it s?\n",
      "\n",
      "THENLAWIUS:\n",
      "\n",
      "SPEED:\n",
      "Why, my lord.\n",
      "\n",
      "TLOUCESTER:\n",
      "They are, undour me, and make you shall difflaction.\n",
      "\n",
      "SARIIGUS:\n",
      "Here'd madam; I will. O, spay I can meen a copjain.\n",
      "\n",
      "RODERIGUS:\n",
      "That'fole, seem.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "I saw them through their parts of love: contempt,\n",
      "To give my son, you doth uncone that it sweet me by thee\n",
      "That I should not trat thee spirits\n",
      "And stat's erecuses the like and by that\n",
      "blowss and melly again, or my time:\n",
      "Lrand to have you all or his brother.\n",
      "\n",
      "CLEOPATRA:\n",
      "No, sinm Ansexarde's judgment in\n",
      "leg outsax labour happier with you: but I'll speak\n",
      "But every body touched with loves to-mone!\n",
      "We was say this fool about him,\n",
      "Epoch: 3/20... Step: 100... Loss: 0.6871... Val Loss: 2.2226\n",
      "Dear:\n",
      "I'll will go with a rrumple butine.\n",
      "\n",
      "IAGO:\n",
      "Steal their hath contemptury and man,\n",
      "Some man what as I am but so it.\n",
      "\n",
      "PETRUCUS:\n",
      "That is disters, though a wife, while he was to besincing.\n",
      "\n",
      "CYMELLAND:\n",
      "Sir, he's wappres yet chindre, my lord; I will\n",
      "not like a munuch the flather, I see your\n",
      "be son. Very me, like a grace:\n",
      "The moundered friends up to best first.\n",
      "\n",
      "EARLIS:\n",
      "Therefore, She will bay me.\n",
      "\n",
      "TIMON:\n",
      "Stey, our dave, a partod with peasun,\n",
      "'tis fair, with his smoke couson their partion us,\n",
      "'nos breathe down of Line is soon again: the bodom shall be to go.\n",
      "\n",
      "SIRICE:\n",
      "Sir, now, this is the heavens, beat your report in every shame\n",
      "And but a writif and a shupf of the very voict.\n",
      "\n",
      "AORA:\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "I say I goder; he was to dinner such too, I was the case,\n",
      "What is in thou dost thou then her fall; and they did thee.\n",
      "\n",
      "TROILUS:\n",
      "Tell you this lie?\n",
      "\n",
      "Third Lord:\n",
      "Present me, it day!\n",
      "\n",
      "Second Citizen:\n",
      "By. How now, my\n",
      "Greaties we would have my hand:\n",
      "She should look it was forman to my death: and loyal\n",
      "Epoch: 5/20... Step: 150... Loss: 0.7034... Val Loss: 2.2513\n",
      "Dear,\n",
      "I'll walk might dangerous grace to day,\n",
      "Who may stand of arms of bargaren, and again,\n",
      "And the mind therefore queen the grace and show to trifters, or their hands with you,\n",
      "To steal so his breath's songem there was envents for't but\n",
      "Cly her death with her prrisin day.\n",
      "\n",
      "CYMBELINE:\n",
      "Be often's headness ship;\n",
      "I knewh a hrature powers, my gentlemen:\n",
      "But made your knees of the wretch go to you.\n",
      "\n",
      "NORFOLK:\n",
      "Wherefore, I'll say thy name.\n",
      "\n",
      "First Gentleman:\n",
      "Your calt those that I do ray, and leave thee you do entigh,\n",
      "On. Till you have found it smeed;\n",
      "And the pissunts and submer shake to see your boy: you have lift a them be\n",
      "In heaven: my lord, look yourself,\n",
      "where the heavens of banished that disposition was,\n",
      "That gloved for his gives with you;\n",
      "Wherefore an I serman's libe with a goodness kning;\n",
      "But gloding in a bise regetyer hut one and to you not but themselves;\n",
      "For though are down to whose sons,\n",
      "Frreneth to your hands at my gunichs;\n",
      "But my not the shimion begin.\n",
      "To make me well, and I fear, I a\n",
      "Epoch: 6/20... Step: 200... Loss: 0.6517... Val Loss: 2.2650\n",
      "Dear:\n",
      "I thought toot: so, peaciunce the bewire which of army:\n",
      "And so substance are a dif reserves; and, shall fair,\n",
      "She should lie ever to your boy.\n",
      "\n",
      "Second Lord:\n",
      "Present, and the love! sir, my lord;\n",
      "To pray, and to be the fixed called outsal doding: what troved\n",
      "As Marrain than he saids but the pawernish; there's noble doyan more prause of it.\n",
      "\n",
      "First Hurder:\n",
      "And I must be your torch before the faults, whose are sen-you are my hands.\n",
      "Pray I, my lord, fay, that ever\n",
      "stay'd armys cer an elsome father, be no still so my lord;\n",
      "And no make my pardon with a stail'd of his eye.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "How fares me stain'd my three,\n",
      "And dargy, my lord, you will mike a suint:\n",
      "I do not see, my lord, and thou\n",
      "her faint, by thy household back.\n",
      "\n",
      "ANNE PAGE:\n",
      "Sweet crest, it being gone are through my but a fill of your confined\n",
      "And not did with my house, where's weaves lost in thy face,\n",
      "But boyom's houses-and to a write to-morrow, ame\n",
      "In great it granged by your brother.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "To me:\n",
      "If any prayer be\n",
      "Epoch: 8/20... Step: 250... Loss: 0.6235... Val Loss: 2.2801\n",
      "Dear: I say!\n",
      "\n",
      "MARK ANTONY:\n",
      "All was fall and meet; so this: but we is our conveyard,\n",
      "That wronk of mine head me fair that kills,\n",
      "And him it out of thy father,\n",
      "But that it were thou lovest his suid of thou\n",
      "have penalm'nt with a ceptious knows,\n",
      "And did you, that hus dastry's armine?\n",
      "\n",
      "CASSIO:\n",
      "\n",
      "MARV CONTURI OF Sheples, some into pir the voices.\n",
      "\n",
      "OCTAVIUS CAESAR:\n",
      "A part to the fortures lugther,\n",
      "And what is it entreat backward; when I hould have his brother's letter\n",
      "Lo come of the great strength I would be do\n",
      "Sispese to All.\n",
      "\n",
      "First Huntingman:\n",
      "What you this lettself so have has the way.\n",
      "\n",
      "Second Lord:\n",
      "Is all yis islant?\n",
      "\n",
      "CALUMATENE:\n",
      "To make thee then: I would not here be not\n",
      "I motion of the clamorous honour,\n",
      "There at you should I be thee, you are enterty on the state\n",
      "That I shall not go word death. But he pity your solemnized and\n",
      "The sichess in fair contempt, thou\n",
      "hast eat innuce to you: I would before you\n",
      "To have me them. love you no sight,\n",
      "Whosedfed the like an adcuper lable-denpartady.\n",
      "\n",
      "CHARMIAN\n",
      "Epoch: 9/20... Step: 300... Loss: 0.6323... Val Loss: 2.2901\n",
      "Dearers;\n",
      "Or trait so fat on them dona blunds: whan they have been upon\n",
      "That obe your action, mistress'd, my lord:\n",
      "Det the chain the flame.\n",
      "\n",
      "CRESSIDA:\n",
      "Ah, thus very her days, all the lement of Norfice,\n",
      "As like a wonder'g ow heaven armands,\n",
      "And one acceoply consoliner;\n",
      "To be your good lords, lordy, and back aro on my sword.\n",
      "\n",
      "Second Lord:\n",
      "That are they so a swall\n",
      "That head us heard but thee, I am not enough,\n",
      "Who cannot early devilstess of the gather's shake.\n",
      "\n",
      "KING HENRY V:\n",
      "And I have all the sign of.\n",
      "\n",
      "FALSTAFF:\n",
      "What, say you shall, we are possess'd, restraimes with her,\n",
      "O, not to ans call'd it;\n",
      "And of recaised that him strings to see her heart,\n",
      "But yet speak love a poorm--o confidence night,\n",
      "On my threater bear.\n",
      "If they say this praised in my save see.\n",
      "\n",
      "GOS ADFORD:\n",
      "I think what his nain out fare-lews all the wise exclamed,\n",
      "Leive him of this heart field thee\n",
      "Do you stoo myself in some remently bountlemen:\n",
      "That holds in a base shame and firmliods lusty to the hadm\n",
      "And promise.\n",
      "\n",
      "Clown:\n",
      "True, she \n",
      "Epoch: 10/20... Step: 350... Loss: 0.7862... Val Loss: 2.3081\n",
      "Dear:\n",
      "No must dear it the creamoly as on lies, as I am sure;\n",
      "That doghts' sport with him, and make a field\n",
      "As I do not, and the hingers, nor kind,\n",
      "Like a such a point, poor a rove to honour,\n",
      "Let me were in this instrain,\n",
      "Too, then well shall cay your majesty.\n",
      "\n",
      "DUKE OF YORK:\n",
      "'Tis citt,, Those man, but a quarel deed contempt,\n",
      "Bring hercud factiss and each abchide her go.\n",
      "\n",
      "CANFIO:\n",
      "I am bear thy bodies than thy didmer's\n",
      "If her presence, you had\n",
      "he content the loves of the time hath a clomale:\n",
      "And dut might be your own daughter, as like as well;\n",
      "But well thy hand that holds my bases with thee, I have not a gor.\n",
      "\n",
      "TROILUS:\n",
      "I must be your restraints, but on my friends, that which mountain us\n",
      "made him by hand hath my life in this chamber.\n",
      "\n",
      "First Gentleman:\n",
      "Your give us befare you will hear thine eyes, she's a mounter;\n",
      "To keep me fair to your fair court:\n",
      "And profession doubter, you will have he flist begg';\n",
      "Unto our toich exfuses, hereich undo a write Soubfellows us;\n",
      "Or, for the mome towers a fupch'd\n",
      "Epoch: 12/20... Step: 400... Loss: 0.5977... Val Loss: 2.3158\n",
      "Dear:\n",
      "I thoughts the wisows fith some eyes, they are of throat\n",
      "Leave shall break it, sir, I say, and I peeplen my blood, even\n",
      "my words from my daughter, aforn me,\n",
      "Go there are morn of my vart of any dead,\n",
      "That all the hand of Namions fear.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Hark of the very father, and been lady!\n",
      "\n",
      "Shephone:\n",
      "In even no port of down, I bun restrain.\n",
      "\n",
      "JUES MARGARET:\n",
      "Nay, Ourgeible name, if all togror of your majesty.\n",
      "\n",
      "DUKE OF YORK:\n",
      "I'll speak nor Helen is his own wroth together,\n",
      "But gain with such an anointed two widdy with you;\n",
      "If my great me, and they have and seem\n",
      "from blein'd mingers, and sind in every knaving'd of fared,\n",
      "Mades is give a doubt for his hand that kingdom.\n",
      "\n",
      "CHARMIAN:\n",
      "An ey! that she will both who'er for offence.\n",
      "\n",
      "CLEOPATRA:\n",
      "No, the wirscheres no state,\n",
      "And now much not constiun's\n",
      "I swears my slee as my shoild to sin as thinking entrit.\n",
      "Prat Yhen my good lord, say the nut of mine story\n",
      "Of burtues behind the slange, or I would not.\n",
      "\n",
      "BERTRAM:\n",
      "Faresheless I should have not to t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Step: 450... Loss: 0.5537... Val Loss: 2.3316\n",
      "Dear:\n",
      "Ay, sir, came command this pearact, who keng it perron.\n",
      "\n",
      "Second Servingman:\n",
      "By these twongher-mand, with my wearth\n",
      "To great, sir, as if entreat basion! guilty, if all the opposition and tell us you know,\n",
      "That in the gods behomit of any boar and gid.\n",
      "\n",
      "MALVOLIO:\n",
      "Nay, cun ement the way nore.\n",
      "\n",
      "TROILUS:\n",
      "I cannat to people; who hep crow Herrible princes,\n",
      "As let me beguiled them, in he's in the gone.\n",
      "\n",
      "LLONCESTER:\n",
      "I will not way whiphes; but who knows no peacle.\n",
      "\n",
      "MALVOLIO:\n",
      "Nay, twise e must donouge, let him by heaven's and fife, with his amazed: he remember,\n",
      "She sent great are down beacely here; and, no more than are,\n",
      "I'll struck from every kingdom, had wor ever\n",
      "straight take it: and given\n",
      "Go him so impudent. If it not fair heast that high hands,\n",
      "That it were thou wouldst bear. I had not more daughter gove\n",
      "The music convening till be her. but your majesty.\n",
      "\n",
      "DUKE OF YORK:\n",
      "I'll prove beauty head; I think you, sir;\n",
      "I to have my hands in burious love: if he be patiante's\n",
      "into thy patent, the way \n",
      "Epoch: 15/20... Step: 500... Loss: 0.5829... Val Loss: 2.3561\n",
      "Dear:\n",
      "No, this is much again honour, and all the nurse\n",
      "To reath and my Lord of him should not be proud to sleep, and so it some last.\n",
      "\n",
      "BANQUO:\n",
      "Decrie, and make o pent wife brought me; Like us brought it is;\n",
      "Or, being more procees.\n",
      "\n",
      "OCTAVIUS CAESAR:\n",
      "If you shall have my guntlemen: so furd it my meen\n",
      "Chat the cast a will about his conferned time and thee.\n",
      "\n",
      "PANDARUS:\n",
      "I'll prepare him condemn'd\n",
      "Laid and line eless action; and they, are too lamon\n",
      "And fermort I dost terrie a master parted that his enemy,\n",
      "Whose bold!\n",
      "\n",
      "CLEOPATRA:\n",
      "\n",
      "ROSALINE:\n",
      "The king is your will, my lord!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What is 'Tis mose than he's putch I am afpers;\n",
      "Come in that pustain procrastes sulking with a good deseit,\n",
      "While my dear peace from the taber is such a knight,\n",
      "When she does they could practise and winned doo.\n",
      "\n",
      "TROILUS:\n",
      "Then let us make him courtier's tay,\n",
      "I would not be safient a lattle daughter to the tame.\n",
      "\n",
      "BALTHASAL:\n",
      "As I have must dismaces a poor than my shall be true.\n",
      "\n",
      "KING LEAR:\n",
      "O Angrable, this is the case\n",
      "Epoch: 16/20... Step: 550... Loss: 0.5473... Val Loss: 2.3638\n",
      "Dear:\n",
      "No, I love so but flowed with thyself?\n",
      "\n",
      "PISTOL:\n",
      "Go some muster Sastend hath thee common thy hands:\n",
      "And king'd affectly tellows, that I have granted with me fortwer;\n",
      "There's good and take a very listle; 'tis fale again,\n",
      "Thou forture that knows to my loyaks: the bruths done along.\n",
      "I hadf he's open against in, or break now,\n",
      "Three have no confident so for a gentleman and juisen,\n",
      "That dust in the brum parsent, good night, and say,\n",
      "Is great secrate of the ceerus.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Why, so see my sures; and my heart, he was sounde her face they call\n",
      "The cobse.\n",
      "\n",
      "KING LEAR:\n",
      "That is the cost.\n",
      "And of thy skort of heaven man as therefore, and\n",
      "I am befaliant thy hand:\n",
      "And bound sird the lustre not it do. thy father that stay'd and soo.\n",
      "\n",
      "TROILUS:\n",
      "The bodies have I from me all.\n",
      "\n",
      "First Gentleman:\n",
      "Hast thou speak.\n",
      "\n",
      "BEATRICE:\n",
      "I'll see your reason's fools know you all entertainment\n",
      "This but my preceise yourself and fires his brother\n",
      "And swent to my lord; you will af ever me\n",
      "So feel in this dingle sister \n",
      "Epoch: 18/20... Step: 600... Loss: 0.5476... Val Loss: 2.3783\n",
      "Dear:\n",
      "I'll was counton o'er of them.\n",
      "\n",
      "NORFOLK:\n",
      "The mountest here; and, as Satrered marry, I thought\n",
      "To stirl profit them, lik us well prepare his gad\n",
      "let distrached and with thy nature\n",
      "To men throw much great peace: you beseech my fallots and fellows up\n",
      "to she'p to-light prayers be sounery\n",
      "That thou bef'sen the steell present will be tore;\n",
      "If thou shall need be with thrit.\n",
      "\n",
      "ABHORLOT:\n",
      "A troe, and such a tritter title raster; and make\n",
      "An our contreaty diegely ming to as well eyes me\n",
      "That thou here two villain than I should ever.\n",
      "This myself would extraition, and to see Purtol! therefore wear\n",
      "The cruse of thee, and her dear ind a wife in the devengents,\n",
      "and was fair against a honour of justice and to be fool's happition.\n",
      "\n",
      "BASDIANS:\n",
      "Why should not got with within me, that are not to see't be for the die\n",
      "me will entreatable,\n",
      "Bring me through I may proper'd be possess'd,\n",
      "That dogh'd in fallous cort of Duplings.\n",
      "\n",
      "SPEED:\n",
      "I know thee and what I would make her bid be won no sweetly death:\n",
      "But sucf a \n",
      "Epoch: 19/20... Step: 650... Loss: 0.5391... Val Loss: 2.3914\n",
      "Deares;\n",
      "Look, the masters in thy father, as if he lay he searf'\n",
      "Thath every one single sister. Where was came full of my cousin\n",
      "Take me well.\n",
      "\n",
      "CLEOPATRA:\n",
      "I think that on your gract noble his lovis arainst?\n",
      "\n",
      "PINO:\n",
      "I think that we do not saw me for their gates, and given much here?\n",
      "\n",
      "CLEOPATRA:\n",
      "Dear greatness and hopes, indeed:\n",
      "Look you will unlend you, and loss of power you shall not mine;\n",
      "And dearly tordy caught up.\n",
      "\n",
      "BEATRICE:\n",
      "Now, by my hope.\n",
      "\n",
      "MALVOLIO:\n",
      "Nay, but any saying the preserved name?\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "\n",
      "DUKE ORSINO:\n",
      "Corrupt me to that rove them too: I have got her.\n",
      "\n",
      "NORFOLK:\n",
      "The queen by any shall not beew the propessing\n",
      "your least shore;\n",
      "For not ght very wife, contence\n",
      "Your children with their grace?\n",
      "\n",
      "CHARMINAN:\n",
      "Even now, As afe me my lord; I thought\n",
      "Therefore I shall be fallous with a copesion of the hand:\n",
      "And bark to have seat your giin? here in yourself angor.\n",
      "\n",
      "THMALLUTES:\n",
      "What isit!' your aum by thy father's options.\n",
      "\n",
      "TIMON:\n",
      "That's yet outho?\n",
      "\n",
      "WARWICK:\n",
      "I saw that to tween me na\n",
      "Epoch: 20/20... Step: 700... Loss: 0.7069... Val Loss: 2.4097\n",
      "Dear:\n",
      "I think the adversage trus to you, gray I do\n",
      "Go say we have done all that you would be your bound\n",
      "We'lr not died from the taber that thy chommand. I do not descred them.\n",
      "\n",
      "PIRONIUS:\n",
      "I hope as thinking\n",
      "that he cannot see:\n",
      "And, as in death well and a wife that I shall meet, some break\n",
      "To feed before the subjocties and thy soul, as well\n",
      "dishome himself to that at my beauty: I will peace;\n",
      "But, for whose fattungs I should not live broo have for the fallow\n",
      "Mothle sight, if behald\n",
      "the king as I am sure;\n",
      "And there's got command.\n",
      "\n",
      "MISTRESS QUICKLY:\n",
      "Come, lords, sometime to poor Mess. Vell; I was to be\n",
      "both Shoulder and gold,\n",
      "Nor his rink, my loed, the wird and open a pirch\n",
      "The story will be true, inderd, so, peace:\n",
      "And I me, as mine own single sight, if you are jealously,\n",
      "And charge or the noble parts of losg.\n",
      "\n",
      "CLAUDIO:\n",
      "I heard nurse falling petsion, yours:\n",
      "Yours not poaconse fellow, with her truth, he is backly would not bed\n",
      "And party with what we no go trye alike a to-brought; which was we ba\n"
     ]
    }
   ],
   "source": [
    "train(lstm_model, text_as_int, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnI-lDmFFcpd"
   },
   "source": [
    "##### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5g6o_-6aMA0",
    "outputId": "596df67c-b963-45b1-c5ee-4eb0ed4ac90d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore them that fellow\n",
      "As I lose a woman sooner of the lead we are exarge,\n",
      "To stay a wissius some so shipler' plames at common friends, my boinmes the payf is a chinter will emtunce, and farch at shall pood leave performs, and with their futy, good common.\n",
      "Sir, and they he love to their same clance of our read;\n",
      "I think it actruar of this body so brow of this rather: how have thee all oursown.\n",
      "\n",
      "BASSANIO:\n",
      "Had when should I dight\n",
      "Speat for you, but where I will: that is an my swown to you.\n",
      "\n",
      "GLOUCES\n"
     ]
    }
   ],
   "source": [
    "print(sample(vanilla_model, 500, prime='The', top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7WSq-vXZPJW",
    "outputId": "e13d86d7-48c9-492b-d41e-2a4bd4877627",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's\n",
      "more her deliver your chains:\n",
      "I am Cleapor, and her wence andich\n",
      "And dore is moved some broth\n",
      "So umparty dow my father, one it enemy that it as me\n",
      "More than your heart, which now does,\n",
      "Agest in the kingdom.\n",
      "\n",
      "LOONSAMONANO:\n",
      "O, I will not constience?\n",
      "\n",
      "LAUNTHAS:\n",
      "OF, it is with the truth, he may contein;\n",
      "Hent in this fortune with consucien of the line:\n",
      "That sons was not hope I gentle of the clame.\n",
      "Here is my good at the vlither\n",
      "With so swear it may well enemy of their hands,\n",
      "That thy your wife, t\n"
     ]
    }
   ],
   "source": [
    "print(sample(lstm_model, 500, prime='The', top_k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "- Changing the number of layers: 5 layers just produced nonsense text, maybe the higher number of layers would need significantly higher number of training epochs. 2 layers seem to be fine with 20 epochs and produce almost readable text.\n",
    "- Changing the sequence length: 20 or 50 does not seem to be different, produces longer texts and fewer dialogue, 100 produces much more dialogue in most samples \n",
    "- Changing the batch size: 10 seems to work fine, 30 produces more random signs in words, 50 looks really good, 100 too\n",
    "- 2 layers, batchsize 50 and sequence length 50 was, with the empirically chosen values, the best result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_Assignment_13.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
