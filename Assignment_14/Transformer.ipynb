{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrAyOX0HfCrz"
   },
   "source": [
    "To complete the exercise focus on the parts that are mentioned in questions. You don't need to understand everything to its fullest here. Even if it's nice to know. The following file loads the english/german sentence pairs and prints out an example of what a pair looks like. Note that for fast training we cut the sentences down to pairs where the english text starts with a personal pronoun and the correspoding form of \"to be\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eIHvYMZrfNat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 195847 sentence pairs\n",
      "Trimmed to 11727 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7046\n",
      "ger 4484\n",
      "['Ich bin zutiefst in dich verliebt.', \"I'm deeply in love with you.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./load_languages.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "igtgOuQSEqEZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ciNc4p42fS5_"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src), tgt)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(self.src_embed(src))\n",
    "    \n",
    "    def decode(self, memory, tgt):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "sNcJlQHygpGT"
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([module for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "19_UC5JljAcV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"Pass the input through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "z3vWNYA_jMbh"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features)).to(device)\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features)).to(device)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "uEMdUlL3jfXG"
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "d7xSGjgnkSCH"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = [SublayerConnection(size, dropout) for i in range(2)]\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-23H2KFLk27a"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "7M3Noq7wlCvl"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x\n",
    "        , mask=subsequent_mask(x.shape[-2])))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(m, m, x))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9fPOqOQe15D"
   },
   "source": [
    "**Exercise 1a)** Complete the attention method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "kiACIq5Vlzgd"
   },
   "outputs": [],
   "source": [
    "def attention(value, key, query, mask = None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    # fill in the gaps\n",
    "    d_k = key.shape[3]\n",
    "    # what is inside the softmax\n",
    "    #print(value.shape, key.shape, query.shape)\n",
    "    scores = torch.matmul(query, torch.transpose(key, 2, 3)) / np.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # change all the values where the mask equals 0 to minus infinity (-1e9 is enough)\n",
    "        scores = scores.masked_fill((mask == 0).to(device), -1e9)  \n",
    "    # apply softmax to the right dimension\n",
    "    p_attn = nn.Softmax(dim=1)(scores)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    \n",
    "    # multiply with value\n",
    "    attention = torch.matmul(p_attn, value)\n",
    "    \n",
    "    return attention, p_attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "QMvDOtHgtH2l"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, value, key, query, mask = None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        value, key, query = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (value, key, query))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(value, key, query, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Gvrm5iseJhd"
   },
   "source": [
    "**Exercise 1d)** Visualize the mask and explain what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "o2P0eJrrry7h"
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_mask(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result 1d):**<br>\n",
    "The mask results in the upper right values over the diagonal to be set to \"-inf\".<br>\n",
    "This is needed, so that the masked self-attention in the decoder does not get information on future words in the same batch during training, that it should not be having information about. <br>\n",
    "The Trues in the lower left corner stand for the prior words, that the decoder should have information about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "wOrELpc4EgmE"
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ZxbblmhOVCv0"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implements the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "BdmdRkFnVN5H"
   },
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    print(tgt_vocab)\n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "_YqhHqoAHlDo"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    # converts a string into a tensor\n",
    "    # the options for lang are either input_lang or output_lang\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    sen_len = len(indexes)\n",
    "    # fill the tensor with EOS_tokens at the end, s.t. it has length 10\n",
    "    indexes.extend([EOS_token for _ in range(10-sen_len)])\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    input_tensor = input_tensor.permute(1,0)\n",
    "    target_tensor = target_tensor.permute(1,0)\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def outputTensorFromTGT(tgt):\n",
    "    # converts the tgt to an output tensor, with which we can compute the loss\n",
    "    # think about what happens here. 4484 =  output_lang.n_words is the number of german words in our dictionary\n",
    "    tgt_list = []\n",
    "    bs = tgt.shape[0]\n",
    "    for i in range(bs):\n",
    "        sentdist_tensor = torch.cat([torch.from_numpy(np.eye(1,output_lang.n_words,index.item())).unsqueeze(0)\n",
    "                           for index in tgt[i,:]], dim = 1)\n",
    "        tgt_list.append(sentdist_tensor)\n",
    "    return torch.cat(tgt_list, dim = 0).float()\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "def train(pair, batch_size, sample = False):\n",
    "    src, tgt = pair\n",
    "    src.to(device)\n",
    "    tgt.to(device)\n",
    "    tgt_tensor = outputTensorFromTGT(tgt).to(device)\n",
    "    decoder_input = torch.tensor([[SOS_token] for _ in range(batch_size)], device=device)\n",
    "    if not sample:\n",
    "        decoder_input = torch.cat([decoder_input, tgt], dim = 1)\n",
    "    else:\n",
    "        cat_list = [decoder_input]\n",
    "        gen_list = []\n",
    "    memory = transformer.encode(src)\n",
    "    if sample:\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output = transformer.decode(memory, decoder_input)\n",
    "            gen = transformer.generator(decoder_output[:,-1])\n",
    "            gen_list.append(gen.unsqueeze(1))\n",
    "            pred = (gen.argmax(dim = 1)).unsqueeze(1)\n",
    "            cat_list.append(pred)\n",
    "            decoder_input = torch.cat(cat_list, dim = 1)\n",
    "        output = torch.cat(gen_list, dim = 1)\n",
    "    else:\n",
    "        decoder_output = transformer.decode(memory, decoder_input)\n",
    "        gen = transformer.generator(decoder_output[:,:10,:])\n",
    "        output = gen\n",
    "    loss = criterion(output, tgt_tensor)\n",
    "    return loss, decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "R9vypkIXVqz_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transformer = make_model(input_lang.n_words, output_lang.n_words, 2 , d_model = 512, d_ff = 512, h = 4)\n",
    "transformer.to(device)\n",
    "\n",
    "optimizer = optim.Adam(transformer.parameters())\n",
    "criterion = nn.KLDivLoss(reduction = 'batchmean')\n",
    "\n",
    "n_pairs = 64000 # number of training pairs\n",
    "batch_size = 512 \n",
    "\n",
    "#--------------\n",
    "# Create Batch\n",
    "#--------------\n",
    "\n",
    "\n",
    "training_pairs = []\n",
    "for i in range(n_pairs // batch_size):\n",
    "    batch_pairs = [tensorsFromPair(random.choice(pairs)) for _ in range(batch_size)] \n",
    "    batch_input  = torch.cat([pair[0] for pair in batch_pairs], dim = 0)\n",
    "    batch_tgt = torch.cat([pair[1] for pair in batch_pairs], dim = 0)\n",
    "    training_pairs.append((batch_input, batch_tgt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "S3nbew_TGn-p"
   },
   "outputs": [],
   "source": [
    "def evaluate(pair, showTgt = False, print_ = True):\n",
    "    transformer.eval()      # disable dropout\n",
    "    inputs = tensorsFromPair(pair)\n",
    "    if print_:\n",
    "        print(\"Example: Input -> Output:\")\n",
    "        print(pair[0])\n",
    "        output_sent ='> '\n",
    "        if showTgt:\n",
    "              print('- '+pair[1])\n",
    "    else:\n",
    "        output_sent = ''\n",
    "    _ , output = train(inputs, batch_size = 1, sample = True)\n",
    "    \n",
    "    for word in output.squeeze(0):\n",
    "        if(word.item() == EOS_token):\n",
    "            # don't print EOS at the end\n",
    "            break\n",
    "        if(word.item() != SOS_token):\n",
    "            # don't print SOS at the beginning\n",
    "            output_sent += output_lang.index2word[word.item()]+' '\n",
    "    return (output_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1a)** Train the Transformer for 5 epochs. (10 Epochs used here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "R4mooxOQWMHa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1][25/125][Loss: 39.50674057006836][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Ich mache das nicht wegen dem Geld.\n",
      "> I'm I'm I'm I'm I'm \n",
      "[Epoch: 1][50/125][Loss: 29.56402015686035][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Ich bin auch hier.\n",
      "> not not not to to to to to to to \n",
      "[Epoch: 1][75/125][Loss: 26.092172622680664][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Du bist so ein Feigling!\n",
      "> I'm not a a a a you. \n",
      "[Epoch: 1][100/125][Loss: 22.278085708618164][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Sie ist ein sehr schüchternes Mädchen.\n",
      "> I am a a a a a a a a \n",
      "[Epoch: 1][125/125][Loss: 16.4414005279541][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Du bist unbegabt.\n",
      "> You're a good good good good good good good good \n",
      "[Epoch: 2][25/125][Loss: 10.861800193786621][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Ich bin viel größer als Tom.\n",
      "> I'm taller than I am. \n",
      "[Epoch: 2][50/125][Loss: 7.257593631744385][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Er ist inkompetent.\n",
      "> He's not a good at all. \n",
      "[Epoch: 2][75/125][Loss: 4.752066135406494][Time per epoch: 00:01:40]\n",
      "Example: Input -> Output:\n",
      "Ich bin sehr neugierig.\n",
      "> I'm very good at the moment. \n",
      "[Epoch: 2][100/125][Loss: 3.0900158882141113][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Ich kämpfe.\n",
      "> I'm not a good at all. \n",
      "[Epoch: 2][125/125][Loss: 2.1047651767730713][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Er ist immer ordentlich gekleidet.\n",
      "> He's always always always always always always always always always \n",
      "[Epoch: 3][25/125][Loss: 1.4649925231933594][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Ich werde heute Nacht zu Hause bleiben.\n",
      "> I'm going to be here Tom soon. \n",
      "[Epoch: 3][50/125][Loss: 1.117594838142395][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Du bist merkwürdig.\n",
      "> You're not a lot of you think of am. \n",
      "[Epoch: 3][75/125][Loss: 0.8384884595870972][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Wir sind noch in Boston.\n",
      "> We're not a long as a long as long as \n",
      "[Epoch: 3][100/125][Loss: 0.6127830147743225][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Sie sind unter Freunden.\n",
      "> You're not going to be friends. \n",
      "[Epoch: 3][125/125][Loss: 0.504656970500946][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Wir gehen nicht ohne euch.\n",
      "> We're not going to be a lot of you. \n",
      "[Epoch: 4][25/125][Loss: 0.3960825502872467][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Wir ziehen nächsten Monat um.\n",
      "> We're moving in the next month. \n",
      "[Epoch: 4][50/125][Loss: 0.3557753264904022][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Sie sind aggressiv.\n",
      "> You're not in the same age as you. \n",
      "[Epoch: 4][75/125][Loss: 0.2949027419090271][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Ich bin nicht die Besitzerin.\n",
      "> I'm not going to do it at all. \n",
      "[Epoch: 4][100/125][Loss: 0.2426959127187729][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Ich mische mich da nicht ein.\n",
      "> I'm not going to speak a French now. \n",
      "[Epoch: 4][125/125][Loss: 0.21592718362808228][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Wir haben kein Toilettenpapier mehr.\n",
      "> We're not going to be a whole world. \n",
      "[Epoch: 5][25/125][Loss: 0.19935080409049988][Time per epoch: 00:01:40]\n",
      "Example: Input -> Output:\n",
      "Ich bin eine Gefangene.\n",
      "> I'm very much of the same life. \n",
      "[Epoch: 5][50/125][Loss: 0.18859392404556274][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Er beneidet sie um ihr Talent.\n",
      "> He's always making that you are. \n",
      "[Epoch: 5][75/125][Loss: 0.16241702437400818][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Sie ist äußerst kälteempfindlich.\n",
      "> She's exceedingly sensitive to the cold. \n",
      "[Epoch: 5][100/125][Loss: 0.14008983969688416][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Ich bin ein Nichtsnutz.\n",
      "> I'm afraid of you a lot of person. \n",
      "[Epoch: 5][125/125][Loss: 0.12612105906009674][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Er ist der geizigste Mensch, den ich kenne.\n",
      "> He's the laziest person I know. \n",
      "[Epoch: 6][25/125][Loss: 0.11784132570028305][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Wir verschwenden unsere Zeit.\n",
      "> We're wasting a lot of our lot of our lot \n",
      "[Epoch: 6][50/125][Loss: 0.11750543117523193][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Ich fürchte, das verstehe ich nicht.\n",
      "> I'm afraid I can't make it out. \n",
      "[Epoch: 6][75/125][Loss: 0.1086466833949089][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Ich bin keine Künstlerin.\n",
      "> I'm not a lot of money. \n",
      "[Epoch: 6][100/125][Loss: 0.09403688460588455][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Ich bin sehr froh, wieder zu Hause zu sein.\n",
      "> I'm very glad to be a meeting. \n",
      "[Epoch: 6][125/125][Loss: 0.08932469040155411][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Ich bin Englischlehrerin.\n",
      "> I'm a little bit of a little tipsy. \n",
      "[Epoch: 7][25/125][Loss: 0.08479823172092438][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Du hast absolut recht bezüglich seines Charakters.\n",
      "> You're absolutely right about his character. \n",
      "[Epoch: 7][50/125][Loss: 0.07834096997976303][Time per epoch: 00:01:47]\n",
      "Example: Input -> Output:\n",
      "Wir freuen uns ja so für euch!\n",
      "> We're so much of so much of so much so \n",
      "[Epoch: 7][75/125][Loss: 0.07385574281215668][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Er ist bis an die Zähne bewaffnet.\n",
      "> He's not the same age as you are. \n",
      "[Epoch: 7][100/125][Loss: 0.07183081656694412][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Ich bin froh, dass du unversehrt bist.\n",
      "> I'm glad to hear that you came here. \n",
      "[Epoch: 7][125/125][Loss: 0.0746186301112175][Time per epoch: 00:01:45]\n",
      "Example: Input -> Output:\n",
      "Du bist ein braves Mädchen.\n",
      "> You're a good at a good mood. \n",
      "[Epoch: 8][25/125][Loss: 0.06657683849334717][Time per epoch: 00:01:40]\n",
      "Example: Input -> Output:\n",
      "Wir sind in Boston.\n",
      "> We're not in the same age as you are. \n",
      "[Epoch: 8][50/125][Loss: 0.06451529264450073][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Er ist ein aggressiver Mensch.\n",
      "> He's a big fan of American cooking. \n",
      "[Epoch: 8][75/125][Loss: 0.05980391055345535][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Ich bin so stolz, dass sie die Meine ist.\n",
      "> I'm proud of my son of my success. \n",
      "[Epoch: 8][100/125][Loss: 0.058436471968889236][Time per epoch: 00:01:41]\n",
      "Example: Input -> Output:\n",
      "Ich bin mir nicht sicher, warum.\n",
      "> I'm not sure of his success. \n",
      "[Epoch: 8][125/125][Loss: 0.05335084721446037][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Ich werde Ihre Hilfe benötigen.\n",
      "> I'm going to be here for help. \n",
      "[Epoch: 9][25/125][Loss: 0.05354277789592743][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Er ist jetzt wohlhabend.\n",
      "> He's a good at the moment. \n",
      "[Epoch: 9][50/125][Loss: 0.054912298917770386][Time per epoch: 00:01:44]\n",
      "Example: Input -> Output:\n",
      "Ihr seid inkompetent.\n",
      "> You're not going to be a Canadian. \n",
      "[Epoch: 9][75/125][Loss: 0.052162304520606995][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Wir sind noch nicht so hungrig.\n",
      "> We're not so much of you are. \n",
      "[Epoch: 9][100/125][Loss: 0.04840303957462311][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Er ist auch in Japan sehr berühmt.\n",
      "> He's also very famous in Japan. \n",
      "[Epoch: 9][125/125][Loss: 0.041647959500551224][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Du siehst gut aus!\n",
      "> You're looking for our passports. \n",
      "[Epoch: 10][25/125][Loss: 0.04301353916525841][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Wir sind den Naturgesetzen unterworfen.\n",
      "> We're not a lot of Tom. \n",
      "[Epoch: 10][50/125][Loss: 0.04266117513179779][Time per epoch: 00:01:42]\n",
      "Example: Input -> Output:\n",
      "Sie wird immer hübscher.\n",
      "> You're getting in the piano. \n",
      "[Epoch: 10][75/125][Loss: 0.03960473835468292][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Ich bin auf alles eingestellt.\n",
      "> I'm ready to be a relationship. \n",
      "[Epoch: 10][100/125][Loss: 0.0410882905125618][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Wir gehen nirgendwohin.\n",
      "> We're not going to leave any younger. \n",
      "[Epoch: 10][125/125][Loss: 0.037673115730285645][Time per epoch: 00:01:43]\n",
      "Example: Input -> Output:\n",
      "Du hast hier keinen Zutritt!\n",
      "> You're not allowed in the whole world. \n",
      "Loss plot:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "def timer(progress, iterations):\n",
    "    now = time.time()-start_time\n",
    "    now = now*iterations/progress\n",
    "    std = now // 3600\n",
    "    min = (now // 60) % 60\n",
    "    sec = now % 60\n",
    "    return int(std), int(min), int(sec)\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "log = 25       # when to show training status\n",
    "epochs = 10     # how many epochs to train\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for i,pair in enumerate(training_pairs):\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = train(pair, batch_size = batch_size)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        losses.append(loss)\n",
    "        if i% log == log-1:\n",
    "            print(\"[Epoch: {}][{}/{}][Loss: {}][Time per epoch: {:02d}:{:02d}:{:02d}]\".format(\n",
    "                epoch+1, i+1, int(n_pairs/batch_size), total_loss/log, *timer(i+1,int(n_pairs/batch_size))))\n",
    "            total_loss = 0\n",
    "            pair = random.choice(pairs)\n",
    "            print(evaluate(pair))\n",
    "    start_time = time.time()\n",
    "print('Loss plot:')\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Kkf7VW7i5ued"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Input -> Output:\n",
      "Du bist beharrlich.\n",
      "- You're persevering.\n",
      "> You're persevering. \n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print(evaluate(pair, showTgt = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1b)** Understand input and output: Print the shape of the input and output and explain\n",
    "what each dimension stands for. How does the KL-Divergence compute the loss for the\n",
    "output? Think about how the tensor represents a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shapes: (Sequence: torch.Size([1, 10]) ,Target: torch.Size([1, 10]) )\n",
      "The first dimension is the batch size, the second dimension is the maximal sentence length.\n",
      "Output Shape: torch.Size([1, 11])\n",
      "The first dimension is the batch size, the second dimension is the sentence length.\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "transformer.eval()      # disable dropout\n",
    "inputs = tensorsFromPair(pair)\n",
    "print(\"Input Shapes: (Sequence:\",inputs[0].shape, \",Target:\",inputs[1].shape,\")\")\n",
    "print(\"The first dimension is the batch size, the second dimension is the maximal sentence length.\")\n",
    "_ , output = train(inputs, batch_size = 1, sample = True)\n",
    "print(\"Output Shape:\",output.shape)\n",
    "print(\"The first dimension is the batch size, the second dimension is the sentence length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 10, 4484])\n",
      "Target Shape: torch.Size([1, 10, 4484])\n",
      "The Inputs for the KL-Divergence loss criterion are of size:\n",
      "    (batchsize, sentence-length, softmax distribution over tokens)\n",
      "So the KL_Divergence looks at the difference in token-distributions between output and target.\n"
     ]
    }
   ],
   "source": [
    "sample=False\n",
    "src, tgt = inputs\n",
    "src.to(device)\n",
    "tgt.to(device)\n",
    "tgt_tensor = outputTensorFromTGT(tgt).to(device)\n",
    "decoder_input = torch.tensor([[SOS_token] for _ in range(1)], device=device)\n",
    "if not sample:\n",
    "    decoder_input = torch.cat([decoder_input, tgt], dim = 1)\n",
    "else:\n",
    "    cat_list = [decoder_input]\n",
    "    gen_list = []\n",
    "memory = transformer.encode(src)\n",
    "if sample:\n",
    "    for i in range(MAX_LENGTH):\n",
    "        decoder_output = transformer.decode(memory, decoder_input)\n",
    "        gen = transformer.generator(decoder_output[:,-1])\n",
    "        gen_list.append(gen.unsqueeze(1))\n",
    "        pred = (gen.argmax(dim = 1)).unsqueeze(1)\n",
    "        cat_list.append(pred)\n",
    "        decoder_input = torch.cat(cat_list, dim = 1)\n",
    "    output = torch.cat(gen_list, dim = 1)\n",
    "else:\n",
    "    decoder_output = transformer.decode(memory, decoder_input)\n",
    "    gen = transformer.generator(decoder_output[:,:10,:])\n",
    "    output = gen\n",
    "print(\"Output Shape:\",output.shape)\n",
    "print(\"Target Shape:\",tgt_tensor.shape)\n",
    "print(\"The Inputs for the KL-Divergence loss criterion are of size:\")\n",
    "print(\"    (batchsize, sentence-length, softmax distribution over tokens)\")\n",
    "print(\"So the KL_Divergence looks at the difference in token-distributions between output and target.\")\n",
    "#loss = criterion(output, tgt_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQVInITOo4V-"
   },
   "source": [
    "**Exercise 1c)** Translate your own german sentence. You can make use of the evaluate function to achive that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "3ZZHZH-DZGjk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Input -> Output:\n",
      "Du bist sauer.\n",
      "- You are angry.\n",
      "> You're a little mad at you. \n"
     ]
    }
   ],
   "source": [
    "pair = [\"Du bist sauer.\", \"You are angry.\"]\n",
    "print(evaluate(pair, showTgt = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib3sNDkvajbQ"
   },
   "source": [
    "**Exercise 2a)** Print the distance from your word to sister in embedding space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "TjFm5Z4li9By"
   },
   "outputs": [],
   "source": [
    "word1 = \"woman\"\n",
    "word2 = \"man\"\n",
    "word3 = \"brother\"\n",
    "word4 = \"sister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1_embed = transformer.tgt_embed(tensorFromSentence(output_lang, word1))\n",
    "word2_embed = transformer.tgt_embed(tensorFromSentence(output_lang, word2))\n",
    "word3_embed = transformer.tgt_embed(tensorFromSentence(output_lang, word3))\n",
    "word4_embed = transformer.tgt_embed(tensorFromSentence(output_lang, word4))\n",
    "word1_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 512]) torch.Size([10, 1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1185.0962, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_embed = word3_embed - word2_embed + word1_embed\n",
    "print(calc_embed.shape,word4_embed.shape)\n",
    "torch.sum((calc_embed - word4_embed)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result 2a):** The Euclidean distance seems to be quite large between the two Embeddings. (But is got smaller by about 600 by changing the epochs from 5 to 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG4HbnWmgZzj"
   },
   "source": [
    "**Exercise 2b)** Complete the following code. Be aware that there will be 10 values for each word even if the input sentence is shorter than 10 words. Thats because the sentences get filled with EOS_tokens at the end such that they all are the same size. Set the tick_label of the bar plot to be the input sentences words (use string.split() to convert strings to lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLayer(\n",
       "  (self_attn): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (src_attn): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (feed_forward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (w_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sublayer): ModuleList(\n",
       "    (0): SublayerConnection(\n",
       "      (norm): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): SublayerConnection(\n",
       "      (norm): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): SublayerConnection(\n",
       "      (norm): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.decoder.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 10])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.decoder.layers[0].src_attn.attn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "pH2TlFlLZyVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Ich bin das zweitälteste von drei Kindern.\n",
      "Output sentence: I'm the second oldest of three children. \n",
      "Word for attention:  second\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "output = evaluate(pair, showTgt = True, print_ = False)\n",
    "sentence = pair[0].split()\n",
    "which_word = 2\n",
    "output_sentence = output.split()\n",
    "print('Input sentence: {}'.format(pair[0]))\n",
    "print('Output sentence: {}'.format(output))\n",
    "print(\"Word for attention: \",output_sentence[which_word])\n",
    "att_tensor = transformer.decoder.layers[0].src_attn.attn[0].data\n",
    "att_tensor = att_tensor.to('cpu').numpy()\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "x = np.arange(att_tensor.shape[1])\n",
    "width = 0.2\n",
    "labels = sentence\n",
    "for i in range(len(sentence),att_tensor.shape[1]):\n",
    "    labels.append(\"empty\")\n",
    "\n",
    "dist = att_tensor[0][which_word]\n",
    "rects1 = ax.bar(x - 3*width/2, dist, width, label='head 1')\n",
    "dist = att_tensor[1][which_word]\n",
    "rects2 = ax.bar(x - width/2, dist, width, label='head 2')\n",
    "dist = att_tensor[2][which_word]\n",
    "rects3 = ax.bar(x + width/2, dist, width, label='head 3')\n",
    "dist = att_tensor[3][which_word]\n",
    "rects4 = ax.bar(x + 3*width/2, dist, width, label='head 4')\n",
    "    \n",
    "ax.set_ylabel('Word Attention')\n",
    "ax.set_title('Attention weights per head for word: {}'.format(output_sentence[which_word]))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sentence)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
