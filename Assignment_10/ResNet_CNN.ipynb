{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLike(nn.Module):\n",
    "  def __init__(self, depth_n):\n",
    "    super(ResNetLike, self).__init__()\n",
    "    self.start = nn.Sequential(OrderedDict([('conv0', nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)),\n",
    "                ('relu0', nn.LeakyReLU()),\n",
    "                ('bn0', nn.BatchNorm2d(16))]))\n",
    "    i_list = [0, 1, 2]\n",
    "    self.repetitions = len(i_list * 2 * depth_n)\n",
    "    self.block1_list = nn.ModuleList([])\n",
    "    self.block2_list = nn.ModuleList([])\n",
    "    self.identity_upscale_list = nn.ModuleList([])\n",
    "    for i in i_list:\n",
    "        for n in range(2 * depth_n):\n",
    "            i_channels = 16 * (2 ** i)\n",
    "            if n == ((2 * depth_n) -1) and i != i_list[-1]:\n",
    "                last_channels = 16 * (2 ** (i+1))\n",
    "            else:\n",
    "                last_channels = i_channels\n",
    "            b1 = [nn.Conv2d(in_channels=i_channels, out_channels=i_channels, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.LeakyReLU(),\n",
    "                  nn.BatchNorm2d(i_channels),\n",
    "                  nn.Conv2d(in_channels=i_channels, out_channels=i_channels, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.LeakyReLU(),\n",
    "                  nn.BatchNorm2d(i_channels)]\n",
    "            b2 = [nn.Conv2d(in_channels=i_channels, out_channels=i_channels, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.LeakyReLU(),\n",
    "                  nn.BatchNorm2d(i_channels),\n",
    "                  nn.Conv2d(in_channels=i_channels, out_channels=last_channels, kernel_size=3, stride=2, padding=1),\n",
    "                  nn.LeakyReLU(),\n",
    "                  nn.BatchNorm2d(last_channels)]\n",
    "            self.block1_list.append(nn.Sequential(*b1))\n",
    "            self.block2_list.append(nn.Sequential(*b2))\n",
    "            self.identity_upscale_list.append(nn.Conv2d(in_channels=i_channels, out_channels=last_channels, kernel_size=3, stride=2, padding=1))\n",
    "    self.end = nn.Sequential(*[nn.Linear(16 * (2 ** 2), 10), nn.Softmax(dim=10)])\n",
    "                                           \n",
    "\n",
    "  def forward(self, x):\n",
    "    y = self.start(x)\n",
    "    for i in range(self.repetitions):\n",
    "        identity = y\n",
    "        y = self.block1_list[i](y)\n",
    "        y += identity\n",
    "        identity = y\n",
    "        y = self.block2_list[i](y)\n",
    "        y += self.identity_upscale_list[i](identity)\n",
    "        print(y.shape)\n",
    "    return self.end(y.reshape([-1,64]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467da3d5a041457ba4d3c7d5002b8478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "mean, std = torch.mean(x), torch.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape, y.shape)\n",
    "plt.imshow(x[0].permute(1, 2, 0))\n",
    "plt.title(classes[y[0].item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 16, 16])\n",
      "torch.Size([32, 32, 8, 8])\n",
      "torch.Size([32, 32, 4, 4])\n",
      "torch.Size([32, 64, 2, 2])\n",
      "torch.Size([32, 64, 1, 1])\n",
      "torch.Size([32, 64, 1, 1])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-e79bc014fa8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-b0d770222e20>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity_upscale_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 10)"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNetLike(depth_n=1)\n",
    "resnet_model.cuda()\n",
    "# fc_optim = optim.SGD(fc_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "fc_optim = optim.Adam(resnet_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "x, y = x.cuda(), y.cuda()\n",
    "output = resnet_model(x)\n",
    "loss = criterion(output, y)\n",
    "loss.backward()\n",
    "fc_optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    optimizer: optim.Optimizer, \n",
    "    data: Union[DataLoader, Tuple[DataLoader]], \n",
    "    max_epochs: int, \n",
    "    cuda=True):\n",
    "  \n",
    "  use_test = False\n",
    "  if isinstance(data, DataLoader):\n",
    "    train_loader = data\n",
    "  elif isinstance(data, tuple):\n",
    "    if len(data) == 2:\n",
    "      train_loader, test_loader = data\n",
    "      if not isinstance(train_loader, DataLoader):\n",
    "        raise TypeError(f'Expected 1st entry of type DataLoader, but got {type(train_loader)}!')\n",
    "      if not isinstance(test_loader, DataLoader):\n",
    "        raise TypeError(f'Expected 2nd entry of type DataLoader, but got {type(test_loader)}!')\n",
    "      use_test = True\n",
    "    else:\n",
    "      raise ValueError(f'Expected tuple of length 2, but got {len(data)}!')\n",
    "  \n",
    "  \n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  model.train()\n",
    "  losses = []\n",
    "  batch_total = len(train_loader)\n",
    "\n",
    "  for epoch in range(max_epochs):\n",
    "    samples_total = 0\n",
    "    samples_correct = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "      x, y = batch\n",
    "      if cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "      output = model(x)\n",
    "      loss = criterion(output, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      yhat = torch.argmax(output, dim=1)\n",
    "\n",
    "      samples_total += len(y)\n",
    "      samples_correct += torch.sum(yhat == y)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "\n",
    "      if batch_idx % 50 == 0:\n",
    "        acc = float(samples_correct) / float(samples_total)\n",
    "\n",
    "        if use_test:\n",
    "          model.eval()\n",
    "\n",
    "          test_x, test_y = next(iter(test_loader))\n",
    "          if cuda:\n",
    "            test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "          test_output = model(test_x)\n",
    "          test_loss = criterion(test_output, test_y)\n",
    "\n",
    "          test_yhat = torch.argmax(test_output, dim=1)\n",
    "          test_acc = float(torch.sum(test_yhat == test_y)) / float(len(test_y))\n",
    "          \n",
    "          model.train()\n",
    "\n",
    "          sys.stdout.write(f'\\rEpoch: {epoch}/{max_epochs} Step: {batch_idx}/{batch_total} Loss: {loss.item():.6f} Acc: {acc:.2%} Test loss: {test_loss:.6f} Test acc: {test_acc:.2%}')\n",
    "        else:\n",
    "          sys.stdout.write(f'\\rEpoch: {epoch}/{max_epochs} Step: {batch_idx}/{batch_total} Loss: {loss.item():.6f} Acc: {acc:.2%}')\n",
    "\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = cnn_model.cuda()\n",
    "cnn_optim = optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "cnn_losses = train(cnn_model, cnn_optim, (train_loader, test_loader), max_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
