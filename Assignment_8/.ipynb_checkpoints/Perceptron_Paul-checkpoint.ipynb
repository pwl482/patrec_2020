{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3cWwlbatGdm"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.443420Z",
     "start_time": "2018-12-11T12:46:50.570749Z"
    },
    "id": "luPsF5SptGdt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from statistics import mean\n",
    "import random\n",
    "from numpy import linalg as LA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width   class\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://vitalflux.com/convert-sklearn-dataset-pandas-dataframe/\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "names = iris.target_names\n",
    " \n",
    "# Create dataframe using iris.data\n",
    "data = pd.DataFrame(data=iris.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    " \n",
    "# Append class / label data\n",
    "data[\"class\"] = names[iris.target]\n",
    " \n",
    "# Print the data and check for yourself\n",
    "data.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1. Perceptron\n",
    "Implement the Perceptron algorithm using Python (incl. Numpy etc.) and use it on the\n",
    "Iris-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.501147Z",
     "start_time": "2018-12-11T12:46:51.445163Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CpeeFeXKtGdu",
    "outputId": "cf860553-0831-4606-e3ca-81959af4ee2c"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def center_data(self, P_X, N_X):\n",
    "        mean = (np.concatenate((P_X, N_X))).mean()\n",
    "        self.b = mean\n",
    "        return P_X - mean, N_X - mean\n",
    "    \n",
    "    def train(self, P_X, N_X):\n",
    "        P_X, N_X = self.center_data(P_X, N_X)\n",
    "        # Initialization:\n",
    "        w_prime = P_X.mean(axis=0)\n",
    "        # Looping:\n",
    "        while True:\n",
    "            # create copy of w:\n",
    "            w = w_prime.copy()\n",
    "            # select the dataset from which to take v:\n",
    "            percentage = P_X.shape[0] / (P_X.shape[0] + N_X.shape[0])\n",
    "            if random.random() <= percentage: # <- positive set\n",
    "                random_index = random.randint(0, P_X.shape[0] - 1)\n",
    "                v = P_X[random_index,:]\n",
    "                if w @ v <= 0: \n",
    "                    w_prime = w + v\n",
    "            else: # <- negative set\n",
    "                random_index = random.randint(0, N_X.shape[0] - 1)\n",
    "                v = N_X[random_index,:]\n",
    "                if w @ v >= 0:\n",
    "                    w_prime = w - v\n",
    "            # stop criterion:\n",
    "            if LA.norm(w_prime - w) <= self.threshold:\n",
    "                break\n",
    "        self.w = w\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if not (self.w is None or self.b is None):\n",
    "            return (X_test @ self.w - self.b > 0).astype(int)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def accuracy(self, labels, predictions):\n",
    "        return np.mean(labels == predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WaByN8YtGdx"
   },
   "source": [
    "#### Splitting the data into training/test and according to their class memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.517929Z",
     "start_time": "2018-12-11T12:46:51.502925Z"
    },
    "id": "E2-w2GzqtGdy"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]], \n",
    "                                                    data[[\"class\"]], test_size=0.2, random_state=None, stratify=data[[\"class\"]])\n",
    "\n",
    "X_train_setosa = X_train[(y_train=='setosa').values].to_numpy()\n",
    "X_train_versicolor = X_train[(y_train=='versicolor').values].to_numpy()\n",
    "X_train_virginica = X_train[(y_train=='virginica').values].to_numpy()\n",
    "\n",
    "X_test_setosa_v_v = X_test.to_numpy()\n",
    "y_test_setosa_v_v = ((y_test == 'setosa').astype(int).to_numpy()).ravel()\n",
    "\n",
    "X_test_versicolor_virginica = X_test[(y_test!='setosa').values].to_numpy()\n",
    "y_test_versicolor_virginica = ((y_test[(y_test!='setosa').values] == 'versicolor').astype(int).to_numpy()).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the algorithm to seperate Setosa from Versicolour and Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setosa vs Versicolor/Virginica mean accuracy: 0.7333333333333336\n"
     ]
    }
   ],
   "source": [
    "N_X = np.concatenate((X_train_versicolor, X_train_virginica))\n",
    "\n",
    "acc_list = []\n",
    "for i in range(100):\n",
    "    clf_setosa_v_v = Perceptron(threshold = 0.001)\n",
    "    clf_setosa_v_v.train(X_train_setosa, N_X)\n",
    "\n",
    "    y_pred_setosa_v_v = clf_setosa_v_v.predict(X_test_setosa_v_v)\n",
    "\n",
    "    acc_list.append(clf_setosa_v_v.accuracy(y_test_setosa_v_v, y_pred_setosa_v_v))\n",
    "print(\"Setosa vs Versicolor/Virginica mean accuracy:\", np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) What happens if you use the algorithm to seperate Versicolour from Virginica? (Evaluate multiple runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versicolor vs Virginica mean accuracy: 0.5235\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for i in range(100):\n",
    "    clf_versicolor_virginica = Perceptron(threshold = 0.001)\n",
    "    clf_versicolor_virginica.train(X_train_versicolor, X_train_virginica) # versicolor is the positive class\n",
    "\n",
    "    y_pred_versicolor_virginica = clf_versicolor_virginica.predict(X_test_versicolor_virginica)\n",
    "\n",
    "    acc_list.append(clf_setosa_v_v.accuracy(y_test_versicolor_virginica, y_pred_versicolor_virginica))\n",
    "print(\"Versicolor vs Virginica mean accuracy:\", np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)  Find a way to solve the problem and obtain the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2. Multilayer-Perceptron (MLP)\n",
    "Implement a class that builds an MLP with both variable depth D (number of layers) and\n",
    "variable number of neurons ni\n",
    "for each layer i = 1, ..., D. Produce outputs on the ZIPDataset: https://web.stanford.edu/~hastie/ElemStatLearn/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, threshold, depth, layer_width):\n",
    "        self.threshold = threshold\n",
    "        self.depth = depth\n",
    "        if not len(layer_width) == depth:\n",
    "            raise Exception(\"'layer_width' needs to be of length 'depth'\")  \n",
    "        self.layer_width = layer_width\n",
    "        self.network_layers = None\n",
    "        \n",
    "    def center_data(self, P_X, N_X):\n",
    "        mean = (np.concatenate((P_X, N_X))).mean()\n",
    "        self.b = mean\n",
    "        return P_X - mean, N_X - mean\n",
    "    \n",
    "    def train(self, P_X, N_X):\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if not (self.w is None or self.b is None):\n",
    "            return (self.w @ X_test.T - self.b > 0).astype(int)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def accuracy(self, labels, predictions):\n",
    "        return np.mean(labels == predictions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Perceptron.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
